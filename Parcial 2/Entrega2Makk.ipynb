{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librerias y paquetes requidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./origen.csv')\n",
    "test = pd.read_csv('./testear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_join_names(row):\n",
    "    if pd.notna(row):  \n",
    "        cleaned_json = row.replace(\"'\", '\"').strip() \n",
    "        try:\n",
    "            country_list = json.loads(cleaned_json)\n",
    "            names = [country['name'] for country in country_list]\n",
    "            return ', '.join(names)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return 'Invalid JSON'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos\n",
    "## Variables de tipo numericas\n",
    "- average rating\n",
    "- numVotes\n",
    "- isAdult\n",
    "- startYear\n",
    "- endYear\n",
    "- runtimeMinutes\n",
    "- seasonNumber\n",
    "- episodeNumber\n",
    "- ordering\n",
    "- language\n",
    "- isOriginalTitle\n",
    "- budget\n",
    "- popularity\n",
    "- revenue\n",
    "- runtime\n",
    "\n",
    "## Variables de tipo str\n",
    "- titleType\n",
    "- genres_x\n",
    "- directors\n",
    "- writers\n",
    "- adult\n",
    "- genres_y\n",
    "- original_language\n",
    "- production_company\n",
    "- production_country\n",
    "- status\n",
    "- tagline\n",
    "- video\n",
    "\n",
    "## Variables booleanas\n",
    "\n",
    "Todas las columnas son rotuladas de manera numerica\n",
    "Las columnas indice, directors, writer, tagline, language, adult fueron eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(df['genres_x'].str.count(',').max())\n",
    "# Se pueden tener como maximo 3 generos x\n",
    "\n",
    "df[['generox1', 'generox2', 'generox3']] = df['genres_x'].str.split(',', expand=True)\n",
    "df = df.drop('genres_x', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "generox = LabelEncoder()\n",
    "df[\"generox1_encoded\"] = generox.fit_transform(df[\"generox1\"])\n",
    "df[\"generox2_encoded\"] = generox.fit_transform(df[\"generox2\"])\n",
    "df[\"generox3_encoded\"] = generox.fit_transform(df[\"generox3\"])\n",
    "df['generox1'] = df['generox1_encoded']\n",
    "df['generox2'] = df['generox2_encoded']\n",
    "df['generox3'] = df['generox3_encoded']\n",
    "df = df.drop('generox1_encoded', axis = 1)\n",
    "df = df.drop('generox2_encoded', axis = 1)\n",
    "df = df.drop('generox3_encoded', axis = 1)\n",
    "\n",
    "firstValueGenerox1 = df['generox1'].iloc[50]  \n",
    "df['generox1'] = df['generox1'].apply(lambda x: None if x == firstValueGenerox1 else x)\n",
    "\n",
    "firstValueGenerox2 = df['generox2'].iloc[3]  \n",
    "df['generox2'] = df['generox2'].apply(lambda x: None if x == firstValueGenerox2 else x)\n",
    "\n",
    "firstValueGenerox2 = df['generox3'].iloc[3]  \n",
    "df['generox3'] = df['generox3'].apply(lambda x: None if x == firstValueGenerox2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "leAdult = LabelEncoder()\n",
    "df[\"isAdult_encoded\"] = leAdult.fit_transform(df[\"isAdult\"])\n",
    "df['isAdult'] = df['isAdult_encoded']\n",
    "df = df.drop('isAdult_encoded', axis = 1)\n",
    "\n",
    "df = df.drop('adult', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "leTitleType = LabelEncoder()\n",
    "df[\"titleType_encoded\"] = leTitleType.fit_transform(df[\"titleType\"])\n",
    "df['titleType'] = df['titleType_encoded']\n",
    "df = df.drop('titleType_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "leLanguage = LabelEncoder()\n",
    "df[\"language_encoded\"] = leLanguage.fit_transform(df[\"original_language\"])\n",
    "df['original_language'] = df['language_encoded']\n",
    "df = df.drop('language_encoded', axis = 1)\n",
    "\n",
    "firstValueLanguage = df['original_language'].iloc[0]  \n",
    "df['original_language'] = df['original_language'].apply(lambda x: None if x == firstValueLanguage else x)\n",
    "\n",
    "df = df.drop('language', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "leStatus = LabelEncoder()\n",
    "df[\"status_encoded\"] = leLanguage.fit_transform(df[\"status\"])\n",
    "df['status'] = df['status_encoded']\n",
    "df = df.drop('status_encoded', axis = 1)\n",
    "\n",
    "firstValueStatus = df['status'].iloc[0]  \n",
    "df['status'] = df['status'].apply(lambda x: None if x == firstValueStatus else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "leVideo = LabelEncoder()\n",
    "df[\"video_encoded\"] = leAdult.fit_transform(df[\"video\"])\n",
    "df['video'] = df['video_encoded']\n",
    "df = df.drop('video_encoded', axis = 1)\n",
    "\n",
    "firstValueVideo = df['video'].iloc[0]  \n",
    "df['video'] = df['video'].apply(lambda x: None if x == firstValueVideo else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "leAttributes = LabelEncoder()\n",
    "df[\"attributes_encoded\"] = leAdult.fit_transform(df[\"attributes\"])\n",
    "df['attributes'] = df['attributes_encoded']\n",
    "df = df.drop('attributes_encoded', axis = 1)\n",
    "\n",
    "firstValueAtrubutes = df['attributes'].iloc[0] \n",
    "df['attributes'] = df['attributes'].apply(lambda x: None if x == firstValueAtrubutes else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287\n",
      "475\n"
     ]
    }
   ],
   "source": [
    "print(df['writers'].str.count(',').max())\n",
    "# Se pueden tener hasta 1288 escritores\n",
    "\n",
    "print(df['directors'].str.count(',').max())\n",
    "# Se pueden tener hasta 475 directores\n",
    "\n",
    "df = df.drop('writers', axis = 1)\n",
    "df = df.drop('directors', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('tagline', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(row):\n",
    "    if isinstance(row, list) and len(row) > 0:\n",
    "        company_dict = row[0]\n",
    "        if 'name' in company_dict:\n",
    "            return company_dict['name']\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countries'] = df['production_countries'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['companies'] = df['production_companies'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre_y'] = df['genres_y'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column_list(column, key):\n",
    "    keys = []\n",
    "\n",
    "    for i in range(df[column].str.count(', ').max() + 1):\n",
    "        keys.append(key.format(n=i))\n",
    "\n",
    "    df[keys] = df[column].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_column_list('genre_y', 'genre_y_{n:d}')\n",
    "df.drop('genre_y', axis=1, inplace=True)\n",
    "df.drop('genres_y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_column_list('companies', 'companies_{n:d}')\n",
    "df.drop('companies', axis=1, inplace=True)\n",
    "df.drop('production_companies', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_column_list('countries', 'countries_{n:d}')\n",
    "df.drop('countries', axis=1, inplace=True)\n",
    "df.drop('production_countries', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_language', 'status', 'video', 'genre_y_0', 'genre_y_1',\n",
      "       'genre_y_2', 'genre_y_3', 'genre_y_4', 'genre_y_5', 'genre_y_6',\n",
      "       'genre_y_7', 'companies_0', 'companies_1', 'companies_2', 'companies_3',\n",
      "       'companies_4', 'companies_5', 'companies_6', 'companies_7',\n",
      "       'companies_8', 'companies_9', 'companies_10', 'companies_11',\n",
      "       'companies_12', 'companies_13', 'companies_14', 'companies_15',\n",
      "       'companies_16', 'companies_17', 'companies_18', 'companies_19',\n",
      "       'companies_20', 'companies_21', 'companies_22', 'companies_23',\n",
      "       'companies_24', 'companies_25', 'countries_0', 'countries_1',\n",
      "       'countries_2', 'countries_3', 'countries_4', 'countries_5',\n",
      "       'countries_6', 'countries_7', 'countries_8', 'countries_9',\n",
      "       'countries_10', 'countries_11', 'countries_12', 'countries_13',\n",
      "       'countries_14', 'countries_15', 'countries_16', 'countries_17',\n",
      "       'countries_18', 'countries_19', 'countries_20', 'countries_21',\n",
      "       'countries_22', 'countries_23', 'countries_24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyGenre = 'genre_y_{n:d}'\n",
    "key_encodedGenre = 'genre_y_{n:d}_encoded'\n",
    "\n",
    "leGenre = LabelEncoder()\n",
    "for n in range(8):  \n",
    "    column_name = f'genre_y_{n}'\n",
    "    \n",
    "    if column_name in df:\n",
    "        encoded_genrey = f'{column_name}_encoded'\n",
    "        df[encoded_genrey] = leGenre.fit_transform(df[column_name])\n",
    "        df[column_name] = df[encoded_genrey]\n",
    "        df.drop(encoded_genrey, axis=1, inplace=True)\n",
    "\n",
    "        firstValue = df[column_name].iloc[0]  # Obtiene el primer valor de la columna\n",
    "        df[column_name] = df[column_name].apply(lambda x: None if x == firstValue else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyCountries = 'countries_{n:d}'\n",
    "key_encodedCountries = 'countries_{n:d}_encoded'\n",
    "\n",
    "leCountries = LabelEncoder()\n",
    "for n in range(24):  \n",
    "    column_name = f'countries_{n}'\n",
    "    \n",
    "    if column_name in df:\n",
    "        encoded_countries = f'{column_name}_encoded'\n",
    "        df[encoded_countries] = leCountries.fit_transform(df[column_name])\n",
    "        df[column_name] = df[encoded_countries]\n",
    "        df.drop(encoded_countries, axis=1, inplace=True)\n",
    "\n",
    "        firstValue = df[column_name].iloc[0]  # Obtiene el primer valor de la columna\n",
    "        df[column_name] = df[column_name].apply(lambda x: None if x == firstValue else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "          ... \n",
      "977536       0\n",
      "977537    8088\n",
      "977538       0\n",
      "977539       0\n",
      "977540       0\n",
      "Name: companies_0, Length: 977541, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "keyCompanies = 'companies_{n:d}'\n",
    "key_encodedCompanies = 'companies_{n:d}_encoded'\n",
    "\n",
    "leCompanies = LabelEncoder()\n",
    "for n in range(25):  \n",
    "    column_name = f'companies_{n}'\n",
    "    \n",
    "    if column_name in df:\n",
    "        encoded_companies = f'{column_name}_encoded'\n",
    "        df[encoded_companies] = leCompanies.fit_transform(df[column_name])\n",
    "        df[column_name] = df[encoded_companies]\n",
    "        df.drop(encoded_companies, axis=1, inplace=True)\n",
    "\n",
    "print(df['companies_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota** : Se ha decidido dejar los valores nulos en el dataset como tales, en lugar de reemplazarlos por un numero. Por esta razón, se utilizaran modelos que admitan este tipo de dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['averageRating', 'numVotes', 'titleType', 'isAdult', 'startYear',\n",
      "       'endYear', 'runtimeMinutes', 'seasonNumber', 'episodeNumber',\n",
      "       'ordering', 'attributes', 'isOriginalTitle', 'budget',\n",
      "       'original_language', 'popularity', 'revenue', 'runtime', 'status',\n",
      "       'video', 'generox1', 'generox2', 'generox3', 'genre_y_0', 'genre_y_1',\n",
      "       'genre_y_2', 'genre_y_3', 'genre_y_4', 'genre_y_5', 'genre_y_6',\n",
      "       'genre_y_7', 'companies_0', 'companies_1', 'companies_2', 'companies_3',\n",
      "       'companies_4', 'companies_5', 'companies_6', 'companies_7',\n",
      "       'companies_8', 'companies_9', 'companies_10', 'companies_11',\n",
      "       'companies_12', 'companies_13', 'companies_14', 'companies_15',\n",
      "       'companies_16', 'companies_17', 'companies_18', 'companies_19',\n",
      "       'companies_20', 'companies_21', 'companies_22', 'companies_23',\n",
      "       'companies_24', 'companies_25', 'countries_0', 'countries_1',\n",
      "       'countries_2', 'countries_3', 'countries_4', 'countries_5',\n",
      "       'countries_6', 'countries_7', 'countries_8', 'countries_9',\n",
      "       'countries_10', 'countries_11', 'countries_12', 'countries_13',\n",
      "       'countries_14', 'countries_15', 'countries_16', 'countries_17',\n",
      "       'countries_18', 'countries_19', 'countries_20', 'countries_21',\n",
      "       'countries_22', 'countries_23', 'countries_24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Titanic s.r.o.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/22/kk3jgz8n1yn0zwh0vft67d040000gn/T/ipykernel_35374/3308768789.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Crear un modelo de regresión lineal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Entrenar el modelo en los datos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Realizar predicciones en el conjunto de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         raise ValueError(\n\u001b[1;32m   1144\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         )\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ' Titanic s.r.o.'"
     ]
    }
   ],
   "source": [
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Manejar los valores nulos en las columnas numéricas (rellenar con la media)\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y etiquetas de destino (y)\n",
    "X = df.drop('averageRating', axis=1)\n",
    "y = df['averageRating']\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo en los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo (por ejemplo, utilizando el error cuadrático medio)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio: {mse}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
