{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librerias y paquetes requidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./origen.csv')\n",
    "test = pd.read_csv('./testear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos\n",
    "## Variables de tipo numericas\n",
    "- average rating\n",
    "- numVotes\n",
    "- isAdult\n",
    "- startYear\n",
    "- endYear\n",
    "- runtimeMinutes\n",
    "- seasonNumber\n",
    "- episodeNumber\n",
    "- ordering\n",
    "- language\n",
    "- isOriginalTitle\n",
    "- budget\n",
    "- popularity\n",
    "- revenue\n",
    "- runtime\n",
    "\n",
    "## Variables de tipo str\n",
    "- titleType\n",
    "- genres_x\n",
    "- directors\n",
    "- writers\n",
    "- adult\n",
    "- genres_y\n",
    "- original_language\n",
    "- production_company\n",
    "- production_country\n",
    "- status\n",
    "- tagline\n",
    "- video\n",
    "\n",
    "## Variables booleanas\n",
    "\n",
    "Todas las columnas son rotuladas de manera numerica\n",
    "Las columnas indice, directors, writer, tagline fueron eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(df['genres_x'].str.count(',').max())\n",
    "# Se pueden tener como maximo 3 generos x\n",
    "\n",
    "df[['generox1', 'generox2', 'generox3']] = df['genres_x'].str.split(',', expand=True)\n",
    "df = df.drop('genres_x', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "generox = LabelEncoder()\n",
    "df[\"generox1_encoded\"] = generox.fit_transform(df[\"generox1\"])\n",
    "df[\"generox2_encoded\"] = generox.fit_transform(df[\"generox2\"])\n",
    "df[\"generox3_encoded\"] = generox.fit_transform(df[\"generox3\"])\n",
    "df['generox1'] = df['generox1_encoded']\n",
    "df['generox2'] = df['generox2_encoded']\n",
    "df['generox3'] = df['generox3_encoded']\n",
    "df = df.drop('generox1_encoded', axis = 1)\n",
    "df = df.drop('generox2_encoded', axis = 1)\n",
    "df = df.drop('generox3_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "leAdult = LabelEncoder()\n",
    "df[\"isAdult_encoded\"] = leAdult.fit_transform(df[\"isAdult\"])\n",
    "df['isAdult_encoded'].fillna(\"NA\", inplace=True)\n",
    "df['isAdult'] = df['isAdult_encoded']\n",
    "df = df.drop('isAdult_encoded', axis = 1)\n",
    "\n",
    "df = df.drop('adult', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "leTitleType = LabelEncoder()\n",
    "df[\"titleType_encoded\"] = leTitleType.fit_transform(df[\"titleType\"])\n",
    "df['titleType'] = df['titleType_encoded']\n",
    "df = df.drop('titleType_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "leLanguage = LabelEncoder()\n",
    "df[\"language_encoded\"] = leLanguage.fit_transform(df[\"original_language\"])\n",
    "df['original_language'] = df['language_encoded']\n",
    "df = df.drop('language_encoded', axis = 1)\n",
    "\n",
    "df = df.drop('language', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "leStatus = LabelEncoder()\n",
    "df[\"status_encoded\"] = leLanguage.fit_transform(df[\"status\"])\n",
    "df['status'] = df['status_encoded']\n",
    "df = df.drop('status_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "leVideo = LabelEncoder()\n",
    "df[\"video_encoded\"] = leAdult.fit_transform(df[\"video\"])\n",
    "df['video'] = df['video_encoded']\n",
    "df = df.drop('video_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "leAttributes = LabelEncoder()\n",
    "df[\"attributes_encoded\"] = leAdult.fit_transform(df[\"attributes\"])\n",
    "df['attributes'] = df['attributes_encoded']\n",
    "df = df.drop('attributes_encoded', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287\n",
      "475\n"
     ]
    }
   ],
   "source": [
    "print(df['writers'].str.count(',').max())\n",
    "# Se pueden tener hasta 1288 escritores\n",
    "\n",
    "print(df['directors'].str.count(',').max())\n",
    "# Se pueden tener hasta 475 directores\n",
    "\n",
    "df = df.drop('writers', axis = 1)\n",
    "df = df.drop('directors', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('tagline', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(row):\n",
    "    if isinstance(row, list) and len(row) > 0:\n",
    "        company_dict = row[0]\n",
    "        if 'name' in company_dict:\n",
    "            return company_dict['name']\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['genres_y', 'production_companies', 'production_countries'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_join_names(row):\n",
    "    if pd.notna(row):  \n",
    "        cleaned_json = row.replace(\"'\", '\"').strip() \n",
    "        try:\n",
    "            country_list = json.loads(cleaned_json)\n",
    "            names = [country['name'] for country in country_list]\n",
    "            return ', '.join(names)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return 'Invalid JSON'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countries'] = df['production_countries'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['companies'] = df['production_companies'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre_y'] = df['genres_y'].apply(extract_and_join_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column_list(column, key):\n",
    "    keys = []\n",
    "\n",
    "    for i in range(df[column].str.count(', ').max() + 1):\n",
    "        keys.append(key.format(n=i))\n",
    "\n",
    "    df[keys] = df[column].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_column_list('genre_y', 'genre_y_{n:d}')\n",
    "df.drop('genre_y', axis=1, inplace=True)\n",
    "df.drop('genres_y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_column_list('companies', 'companies_{n:d}')\n",
    "df.drop('companies', axis=1, inplace=True)\n",
    "df.drop('production_companies', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['genre_y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/azulmakk/Universidad/Analisis Predictivo/Parcial 2/Entrega2Makk.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/azulmakk/Universidad/Analisis%20Predictivo/Parcial%202/Entrega2Makk.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m extract_column_list(\u001b[39m'\u001b[39m\u001b[39mcountries\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcountries_\u001b[39m\u001b[39m{n:d}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/azulmakk/Universidad/Analisis%20Predictivo/Parcial%202/Entrega2Makk.ipynb#Y110sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mgenre_y\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdrop(\n\u001b[1;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39mlabels,\n\u001b[1;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   5261\u001b[0m         index\u001b[39m=\u001b[39mindex,\n\u001b[1;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39mcolumns,\n\u001b[1;32m   5263\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[1;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39minplace,\n\u001b[1;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m   5266\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_drop_axis(labels, axis, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['genre_y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "extract_column_list('countries', 'countries_{n:d}')\n",
    "df.drop('countries', axis=1, inplace=True)\n",
    "df.drop('production_countries', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['averageRating', 'numVotes', 'titleType', 'isAdult', 'startYear',\n",
      "       'endYear', 'runtimeMinutes', 'seasonNumber', 'episodeNumber',\n",
      "       'ordering', 'attributes', 'isOriginalTitle', 'budget', 'genres_y',\n",
      "       'original_language', 'popularity', 'production_companies',\n",
      "       'production_countries', 'revenue', 'runtime', 'status', 'video',\n",
      "       'generox1', 'generox2', 'generox3', 'countries', 'companies',\n",
      "       'genre_y_0', 'genre_y_1', 'genre_y_2', 'genre_y_3', 'genre_y_4',\n",
      "       'genre_y_5', 'genre_y_6', 'genre_y_7', 'companies_0', 'companies_1',\n",
      "       'companies_2', 'companies_3', 'companies_4', 'companies_5',\n",
      "       'companies_6', 'companies_7', 'companies_8', 'companies_9',\n",
      "       'companies_10', 'companies_11', 'companies_12', 'companies_13',\n",
      "       'companies_14', 'companies_15', 'companies_16', 'companies_17',\n",
      "       'companies_18', 'companies_19', 'companies_20', 'companies_21',\n",
      "       'companies_22', 'companies_23', 'companies_24', 'companies_25',\n",
      "       'countries_0', 'countries_1', 'countries_2', 'countries_3',\n",
      "       'countries_4', 'countries_5', 'countries_6', 'countries_7',\n",
      "       'countries_8', 'countries_9', 'countries_10', 'countries_11',\n",
      "       'countries_12', 'countries_13', 'countries_14', 'countries_15',\n",
      "       'countries_16', 'countries_17', 'countries_18', 'countries_19',\n",
      "       'countries_20', 'countries_21', 'countries_22', 'countries_23',\n",
      "       'countries_24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "key = 'genre_y_{n:d}'\n",
    "key_encoded = 'genre_y_{n:d}_encoded'\n",
    "\n",
    "for i in range(df[key].str.count(', ').max() + 1):\n",
    "    le = LabelEncoder()\n",
    "    df[key_encoded.format(n=i)] = le.fit_transform(df[key.format(n=i)])\n",
    "    df[key.format(n=i)] = df[key_encoded.format(n=i)]\n",
    "    df = df.drop(key_encoded.format(n=i), axis = 1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
